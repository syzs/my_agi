{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 tf.data.Dataset 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List 列表数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 17:56:16.946771: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "for element in dataset:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator 生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def gen():\n",
    "    for i in itertools.count(1):\n",
    "        yield (i, [1] * i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.flat_map_op._FlatMapDataset'>\n",
      "<class 'tensorflow.python.data.ops.take_op._TakeDataset'>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from_generator：创建一个数据集\n",
    "def from_generator(\n",
    "      generator,\n",
    "      output_types=None,\n",
    "      output_shapes=None,...）\n",
    "\n",
    "(tf.TensorShape([]), tf.TensorShape([None]))：生成的数据的Tensor形状\n",
    "tf.TensorShape([]): 表示一个标量（没有维度的数组）\n",
    "tf.TensorShape([None]): 表示一个可变长度的一维数组\n",
    "对应生成器函数返回的元组中的两个元素：第一个元素是一个整数，没有维度，第二个元素是一个列表，其长度可以变化\n",
    "      \n",
    "'''\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    gen,\n",
    "    (tf.int64, tf.int64),\n",
    "    (tf.TensorShape([]), tf.TensorShape([None])))\n",
    "\n",
    "print(type(dataset)) # <class 'tensorflow.python.data.ops.flat_map_op._FlatMapDataset'>\n",
    "print(type(dataset.take(3))) # <class 'tensorflow.python.data.ops.take_op._TakeDataset'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 17:56:17.340408: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, array([1])), (2, array([1, 1])), (3, array([1, 1, 1]))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "dataset.take(n)方法用于从数据集中取出前n个元素\n",
    "as_numpy_iterator()方法则允许你迭代这个数据集，并将其中的Tensor对象转换为NumPy数组\n",
    "list(...)：将迭代器中的所有元素收集到一个Python列表中。\n",
    "'''\n",
    "\n",
    "list(dataset.take(3).as_numpy_iterator())\n",
    "\n",
    "# [(1, array([1])), (2, array([1, 1])), (3, array([1, 1, 1]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = \"files\"\n",
    "FILE_NAMES = ['cowper.txt', 'derby.txt', 'butler.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "'''\n",
    "tf.cast(index, tf.int64): 将一个Tensor从一种数据类型转换为另一种数据类型。在你的代码示例中，tf.cast(index, tf.int64)的作用是将index变量（通常是Python中的整数类型）转换为TensorFlow的int64类型。\n",
    ">>> tf.cast(1, tf.int64)\n",
    "<tf.Tensor: shape=(), dtype=int64, numpy=1>\n",
    "'''\n",
    "def labeler(example, index):\n",
    "    return example, tf.cast(index, tf.int64)  \n",
    "\n",
    "labeled_data_sets = []\n",
    "\n",
    "'''\n",
    "tf.data.TextLineDataset:函数创建一个数据集，它会读取指定文件路径中的文本行。os.path.join(parent_dir, file_name)用于生成每个文件的完整路径。\n",
    "labeled_dataset：使用map方法将labeler函数应用到lines_dataset数据集中的每个元素（即每一行文本）上。这样，每一行文本都会与相应的标签（文件的索引）关联起来。\n",
    "\n",
    "'''\n",
    "for i, file_name in enumerate(FILE_NAMES):\n",
    "    lines_dataset = tf.data.TextLineDataset(os.path.join(parent_dir, file_name))\n",
    "    labeled_dataset = lines_dataset.map(lambda ex: labeler(ex, i))\n",
    "    labeled_data_sets.append(labeled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "这些步骤将所有标记数据集合并成一个单一的数据集，并确保在训练模型时，数据是随机的，每个批次包含64个样本，且数据在每个epoch开始时被打乱一次。\n",
    "这样的数据预处理对于训练高效的机器学习模型是非常重要的，因为它有助于模型更好地泛化到未见过的数据上。\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "BUFFER_SIZE = 50000：这是用于打乱数据集的缓冲区大小。\n",
    "在TensorFlow中，shuffle操作会将数据集中的元素随机排序，以便在训练模型时增加样本的多样性。缓冲区大小决定了在内存中保留多少数据用于打乱。\n",
    "较大的缓冲区可以提供更好的随机性，但也会增加内存的使用。\n",
    "'''\n",
    "BUFFER_SIZE = 50000\n",
    "'''\n",
    "BATCH_SIZE = 64：这是每个批次中的样本数量。\n",
    "在训练模型时，数据通常被分成小批量（batch），每个批次包含一定数量的样本。\n",
    "这样可以更高效地利用内存，并且有助于模型的稳定训练。\n",
    "'''\n",
    "BATCH_SIZE = 64\n",
    "'''\n",
    "TAKE_SIZE = 5000：这个变量没有在代码中直接使用，但它可能用于限制数据集中处理的样本数量，例如，用于调试或测试目的。\n",
    "'''\n",
    "TAKE_SIZE = 5000\n",
    "\n",
    "'''\n",
    "遍历了labeled_data_sets列表中剩余的所有标记数据集，并将每个数据集与all_labeled_data合并。这是通过concatenate方法完成的，它将两个数据集合并为一个单一的数据集。\n",
    "相当于从 [ [], [], []] -> [] ，整合数据集\n",
    "'''\n",
    "all_labeled_data = labeled_data_sets[0] # 第一个数据集\n",
    "for labeled_dataset in labeled_data_sets[1:]: # 从第二个数据集开始遍历\n",
    "    all_labeled_data = all_labeled_data.concatenate(labeled_dataset)\n",
    "\n",
    "\n",
    "'''\n",
    "在合并所有数据集之后，你使用shuffle方法对整个数据集进行打乱。\n",
    "BUFFER_SIZE参数指定了用于打乱操作的缓冲区大小。\n",
    "reshuffle_each_iteration=False参数意味着数据集只会在第一次迭代时被打乱，之后的迭代将不会再次打乱。这通常用于确保在每个epoch（训练周期）开始时数据被随机化，但在同一个epoch内保持固定的顺序。\n",
    "'''\n",
    "all_labeled_data = all_labeled_data.shuffle(\n",
    "    BUFFER_SIZE, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Ah! it were well if in the fishy deep'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b\"Thou slave of woman, manhood's counterfeit,\">, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Fell to the ground, some from the grasp, and some'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'And jealous both lest I should also win'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Their dread approach, for to his tower they bent;'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 17:56:20.669874: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for ex in all_labeled_data.take(5):\n",
    "    print(ex)\n",
    "\n",
    "# 根据 labeler 函数的定义，返回的第一个tensor是string，文章的具体一行的内容，第二个tensor是tf.int64，第几个被迭代的文件\n",
    "# (<tf.Tensor: shape=(), dtype=string, numpy=b'His good housekeeper answered, \"Hector, since you bid me tell you'>, <tf.Tensor: shape=(), dtype=int64, numpy=2>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
